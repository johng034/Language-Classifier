{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the language given an input\n",
    "\n",
    "Link to [dataset](https://www.kaggle.com/zarajamshaid/language-identification-datasst)\n",
    "\n",
    "The dataset contains 1,000 rows for 22 languages (22,000 data points in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import scipy.sparse\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# import streamlit\n",
    "# import pickle\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is your first time using the `nltk` library, uncomment the following cell to download the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Japanese      1000\n",
       "Hindi         1000\n",
       "Pushto        1000\n",
       "Persian       1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Estonian      1000\n",
       "Turkish       1000\n",
       "Swedish       1000\n",
       "Portugese     1000\n",
       "Urdu          1000\n",
       "Romanian      1000\n",
       "Korean        1000\n",
       "Russian       1000\n",
       "Indonesian    1000\n",
       "Spanish       1000\n",
       "Chinese       1000\n",
       "Thai          1000\n",
       "French        1000\n",
       "Latin         1000\n",
       "English       1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Issue*\n",
    "- `nltk.word_tokenize` currently only supports English. This is not a very important issue since most of the langauges have spaces, so they're still tokenized somewhat correctly.\n",
    "- Languages that do not use spaces (such as Chinese and Japanese) are greatly affected by this.\n",
    "\n",
    "### Potential Solutions\n",
    "- For Chinese and Japanese, I could find any packages that specialize in these languages\n",
    "- I do not know enough about all these languages to be certain that they're correctly tokenized.\n",
    "    - I could talk with people who have experience with some of these languages to ensure the data is being processed correctly\n",
    "\n",
    "We will see how the algorithms perform, even with this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will not be including the languages that nltk do not support\n",
    "I may come back to this at a later time to find packages that support the remaining languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Language'] = df.language\n",
    "# df['language'] = df['Language'].apply(lambda x: str.lower(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of languages in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estonian',\n",
       " 'swedish',\n",
       " 'thai',\n",
       " 'tamil',\n",
       " 'dutch',\n",
       " 'japanese',\n",
       " 'turkish',\n",
       " 'latin',\n",
       " 'urdu',\n",
       " 'indonesian',\n",
       " 'portugese',\n",
       " 'french',\n",
       " 'chinese',\n",
       " 'korean',\n",
       " 'hindi',\n",
       " 'spanish',\n",
       " 'pushto',\n",
       " 'persian',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'english',\n",
       " 'arabic']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = df['language'].apply(lambda x: str.lower(x)).unique().tolist()\n",
    "\n",
    "languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of languages supported by `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'README',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_languages = os.listdir(\"C:\\\\users\\\\johng\\\\appdata\\\\roaming\\\\nltk_data\\\\corpora\\\\stopwords\")\n",
    "\n",
    "supported_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection between the two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'French',\n",
       " 'Dutch',\n",
       " 'Turkish',\n",
       " 'Swedish',\n",
       " 'Spanish',\n",
       " 'Indonesian',\n",
       " 'Romanian',\n",
       " 'English',\n",
       " 'Russian']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the intersection between lists\n",
    "final_languages = list(set(languages) & set(supported_languages))\n",
    "final_languages = [lang.capitalize() for lang in final_languages]\n",
    "\n",
    "final_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using 10 languages from the 22 languages in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'We will be using {len(final_languages)} languages from the {len(languages)} languages in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep the rows that have the supported languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.language.isin(final_languages)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    language\n",
       "0  sebes joseph pereira thomas  på eng the jesuit...     Swedish\n",
       "1  de spons behoort tot het geslacht haliclona en...       Dutch\n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...     Turkish\n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  Indonesian\n",
       "4  association de recherche et de sauvegarde de l...      French"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "- Remove special characters from the text\n",
    "- Remove any extra whitespaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(\"[\\[\\[\\]\\]?—\\\"\\\"«»]\", \"\", text)  # Remove special characters\n",
    "    text = text.replace('\\u200b', '')\n",
    "    text = re.sub(\"-\", \" \", text)  # Replace '-' with a space\n",
    "    text = \" \".join(text.split())  # Remove any extra spaces\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>sebes joseph pereira thomas på eng the jesuits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "      <td>French</td>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    language  \\\n",
       "0  sebes joseph pereira thomas  på eng the jesuit...     Swedish   \n",
       "1  de spons behoort tot het geslacht haliclona en...       Dutch   \n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...     Turkish   \n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  Indonesian   \n",
       "4  association de recherche et de sauvegarde de l...      French   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  sebes joseph pereira thomas på eng the jesuits...  \n",
       "1  de spons behoort tot het geslacht haliclona en...  \n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...  \n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  \n",
       "4  association de recherche et de sauvegarde de l...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Text'] = df['Text'].apply(lambda x: preprocess(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_words = df['Cleaned_Text'].apply(lambda x: len(nltk.word_tokenize(x))).tolist()\n",
    "\n",
    "sns.histplot(data=num_words)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=num_words, orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DataFrame\n",
    "Save as Pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./saved-items/df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.clean_text, df.Language, test_size=0.15, random_state=42, \n",
    "    shuffle=True, stratify=df.Language\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616    the hidden wiki herkesin anonim olarak düzenle...\n",
       "372     كانت طالبة نيميسيو أنتونيز وكارمين سيلفا وغارس...\n",
       "8013    الاتصالات صممت أجهزة إرسال متعددة ومستقبلات مت...\n",
       "23      сделал понимания деятельности м ломоносова дол...\n",
       "5839    roissy connaît forte hausse population peut se...\n",
       "                              ...                        \n",
       "8795    omgivningarna runt rouaïsset aabdel jalil huvu...\n",
       "3823    хотя сопровождавший loaded сингл « who loves t...\n",
       "6112    незаконченную рукопись « теории электричества ...\n",
       "4546    şehire gittiklerinde zengin bir kadına dönüşüm...\n",
       "1539    “ gizli kutsal ismin tecellisine mazhar olan t...\n",
       "Name: clean_text, Length: 8500, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = CountVectorizer()\n",
    "# new_X = vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any stopwords in the language\n",
    "for row, col in df.iterrows():\n",
    "    text = col['tokenized_text']\n",
    "    language = col['language']\n",
    "    dropped.append([word for word in text if word not in stopwords.words(language)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtm = pd.DataFrame.sparse.from_spmatrix(new_X, columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline that contains `CountVectorizer()` and `MultinomialNB()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "vkd = vec.fit_transform(X_train)\n",
    "\n",
    "m = MultinomialNB()\n",
    "\n",
    "m.fit(vkd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vv = CountVectorizer()\n",
    "\n",
    "# vk = vv.fit(X_test)\n",
    "\n",
    "# yp = m.predict(vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "nm = 'naive.sav'\n",
    "pickle.dump(m, open(nm, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(text_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_train_pred)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = text_pipeline.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_train_pred)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save classifier using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(text_pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)\n",
    "\n",
    "# OR\n",
    "# file = open(\"classifier.pickle\", \"wb\")\n",
    "# pickle.dump(text_pipeline, file)\n",
    "\n",
    "# OR\n",
    "# file_to_read = open(\"classifier.pickle\")\n",
    "# loaded_object = pickle.load(file_to_read)\n",
    "# file_to_read.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a way to remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Files\n",
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs = sorted(y_train.unique())\n",
    "# file = 'language.sav'\n",
    "# pickle.dump(langs, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(confusion_matrix(y_test, predicted_y, labels=[language.capitalize() for language in final_languages]), \n",
    "#              columns=[language.capitalize() for language in final_languages])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(text):\n",
    "    text = [text]\n",
    "    langs = sorted(y_train.unique())\n",
    "    print(\"Predicted Language: \" + text_pipeline.predict(text)[0])\n",
    "    pred_probs = text_pipeline.predict_proba(text)\n",
    "    pred_df = pd.DataFrame(pred_probs, columns=langs)\n",
    "    \n",
    "    # Plot the probablities\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x=langs, height=pred_probs.reshape(10,), width=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_language('i hope this algorithm works well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs = sorted(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipeline.predict(['hello how are you doing on this fine evening i am doing very well thank you for asking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipeline.predict_proba(['hello how are you doing on this fine evening i am doing very well thank you for asking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipeline.predict(['let us see how well this thing performs'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_probs = text_pipeline.predict_proba(['let us see how well this thing performs'])\n",
    "\n",
    "# pd.DataFrame(pred_probs, columns=langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['je veux savoir comment ce chose fait']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_probs = text_pipeline.predict_proba(['je veux savoir comment ce chose fait'])\n",
    "# pd.DataFrame(pred_probs, columns=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_language('je veux savoir comment ce chose fait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing languages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['ok so I am going to try to trick this thing by writing in different languages.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_language('Daccord I think che non possiamo faire deux chose al mismo tiempo et definitely non due')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['Daccord I think che non possiamo faire deux chose al mismo tiempo et definitely non due']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['Daccord I think che non possiamo faire deux chose al mismo tiempo et definitely non due']))\n",
    "# pred_probs = text_pipeline.predict_proba(['Daccord I think che non possiamo faire deux chose al mismo tiempo et definitely non due'])\n",
    "# pd.DataFrame(pred_probs, columns=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_probs = pred_probs.reshape(10,)c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.bar(x=langs, height=pred_probs, width=0.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Unknown Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['Allora ci sono alcune persone che non capiscono italiano']))\n",
    "# pred_probs = text_pipeline.predict_proba(['Allora ci sono alcune persone che non capiscono italiano'])\n",
    "# pd.DataFrame(pred_probs, columns=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_pipeline.predict(['可能你听不懂']))\n",
    "# pred_probs = text_pipeline.predict_proba(['可能你听不懂'])\n",
    "# pd.DataFrame(pred_probs, columns=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_probs = pred_probs.reshape(10,)\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.bar(x=langs, height=pred_probs, width=0.8)\n",
    "# plt.ylim([0,0.8])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
