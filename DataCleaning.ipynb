{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If this is your first time using the `nltk` library, uncomment the following cell to download the necessary modules. For this notebook, you will need to download the *stopwords* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to [dataset](https://www.kaggle.com/zarajamshaid/language-identification-datasst) on Kaggle.\n",
    "\n",
    "The dataset contains 1,000 rows for 22 languages (22,000 data points in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       1000\n",
       "Spanish       1000\n",
       "Korean        1000\n",
       "Japanese      1000\n",
       "Latin         1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Pushto        1000\n",
       "Chinese       1000\n",
       "Romanian      1000\n",
       "Tamil         1000\n",
       "Estonian      1000\n",
       "Turkish       1000\n",
       "Persian       1000\n",
       "Dutch         1000\n",
       "Arabic        1000\n",
       "Thai          1000\n",
       "Swedish       1000\n",
       "Portugese     1000\n",
       "Hindi         1000\n",
       "French        1000\n",
       "Russian       1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the dataset\n",
    "- `nltk.word_tokenize` currently only supports English. This is not a very important issue since most of the langauges have spaces, so they can still be tokenized.\n",
    "- Languages that do not use spaces to separate words (such as Chinese) are greatly affected by this.\n",
    "\n",
    "For this project, I will only keep the languages that `nltk` currently supports. An idea for a future project would be to include other languages in the dataset with packages that specialize in those languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of languages in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estonian',\n",
       " 'swedish',\n",
       " 'thai',\n",
       " 'tamil',\n",
       " 'dutch',\n",
       " 'japanese',\n",
       " 'turkish',\n",
       " 'latin',\n",
       " 'urdu',\n",
       " 'indonesian',\n",
       " 'portugese',\n",
       " 'french',\n",
       " 'chinese',\n",
       " 'korean',\n",
       " 'hindi',\n",
       " 'spanish',\n",
       " 'pushto',\n",
       " 'persian',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'english',\n",
       " 'arabic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = df['language'].apply(lambda x: str.lower(x)).unique().tolist()\n",
    "\n",
    "languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of languages supported by `nltk`\n",
    "\n",
    "**NOTE:** In order for this to work on your device, it is necessary to find the location where the stopwords are saved in your system and replace the path in quotes with the correct filepath from your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dutch',\n",
       " 'german',\n",
       " 'slovene',\n",
       " 'hungarian',\n",
       " 'romanian',\n",
       " 'kazakh',\n",
       " 'turkish',\n",
       " 'russian',\n",
       " 'README',\n",
       " 'italian',\n",
       " 'english',\n",
       " 'greek',\n",
       " 'tajik',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'finnish',\n",
       " 'danish',\n",
       " 'french',\n",
       " 'swedish',\n",
       " 'azerbaijani',\n",
       " 'spanish',\n",
       " 'indonesian',\n",
       " 'arabic',\n",
       " 'nepali']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Windows\n",
    "# supported_languages = os.listdir(\"C:\\\\users\\\\johng\\\\appdata\\\\roaming\\\\nltk_data\\\\corpora\\\\stopwords\")\n",
    "\n",
    "# Mac OS\n",
    "supported_languages = os.listdir('/Users/johngonzalez/nltk_data/corpora/stopwords')\n",
    "\n",
    "supported_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection between the two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Romanian',\n",
       " 'Indonesian',\n",
       " 'Spanish',\n",
       " 'Turkish',\n",
       " 'Dutch',\n",
       " 'French',\n",
       " 'English',\n",
       " 'Russian',\n",
       " 'Swedish',\n",
       " 'Arabic']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the intersection between lists\n",
    "final_languages = list(set(languages) & set(supported_languages))\n",
    "final_languages = [lang.capitalize() for lang in final_languages]\n",
    "\n",
    "final_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using 10 languages from the 22 languages in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'We will be using {len(final_languages)} languages from the {len(languages)} languages in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep the rows with the supported languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.language.isin(final_languages)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    language\n",
       "0  sebes joseph pereira thomas  på eng the jesuit...     Swedish\n",
       "1  de spons behoort tot het geslacht haliclona en...       Dutch\n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...     Turkish\n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  Indonesian\n",
       "4  association de recherche et de sauvegarde de l...      French"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       1000\n",
       "Indonesian    1000\n",
       "Spanish       1000\n",
       "Arabic        1000\n",
       "Dutch         1000\n",
       "French        1000\n",
       "Turkish       1000\n",
       "Romanian      1000\n",
       "Russian       1000\n",
       "Swedish       1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 10000 data points left.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are a total of {sum(df.language.value_counts())} data points left.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "- Remove special characters from the text\n",
    "- Remove any extra whitespaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(\"[\\[\\[\\]\\]?—\\\"\\\"«»]\", \"\", text)  # Remove special characters\n",
    "    text = text.replace('\\u200b', '')\n",
    "    text = re.sub(\"-\", \" \", text)  # Replace '-' with a space\n",
    "    text = \" \".join(text.split())  # Remove any extra spaces\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>sebes joseph pereira thomas på eng the jesuits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>kemunculan pertamanya adalah ketika mencium ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "      <td>French</td>\n",
       "      <td>association de recherche et de sauvegarde de l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    language  \\\n",
       "0  sebes joseph pereira thomas  på eng the jesuit...     Swedish   \n",
       "1  de spons behoort tot het geslacht haliclona en...       Dutch   \n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...     Turkish   \n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  Indonesian   \n",
       "4  association de recherche et de sauvegarde de l...      French   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  sebes joseph pereira thomas på eng the jesuits...  \n",
       "1  de spons behoort tot het geslacht haliclona en...  \n",
       "2  tsutinalar i̇ngilizce tsuutina kanadada albert...  \n",
       "3  kemunculan pertamanya adalah ketika mencium ka...  \n",
       "4  association de recherche et de sauvegarde de l...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Text'] = df['Text'].apply(lambda x: preprocess(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DataFrame\n",
    "Save as Pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./saved-items/df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
